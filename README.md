**Papers:**

1. "Image Data Classification with Multilayer Perceptrons and Convolutional Neural Networks"
2. "Reproducibility in ML: COMP 551"
Authors: Brandon Park, Sean Li, Yanis Mouazar

**Overview:**
This README encompasses two separate yet interconnected research papers focusing on distinct aspects of machine learning. The first paper delves into image data classification using MLPs and CNNs, whereas the second paper investigates the reproducibility of ML models, specifically comparing softmax and SVM in CNNs.

**Paper 1: Image Data Classification with MLPs and CNNs**
Key Highlights:

Examination of MLP and CNN for image data classification.
In-depth analysis of the CIFAR-10 dataset.
Exploration of activation functions and their impact on model efficiency.
Hyperparameter tuning and its role in model optimization.
Data & Resources:

Utilization of the CIFAR-10 dataset.
Application of machine learning frameworks for model development.


**Paper 2: Reproducibility in ML: COMP 551**
Key Highlights:

Focus on reproducibility in machine learning models.
Comparative study of softmax activation function and linear SVM in CNNs.
Use of datasets such as MNIST, CIFAR-10, and ICML 2013 face expression recognition challenge.
Analysis of model performances and challenges in reproducibility.
Data & Resources:

Reproduction of experiments using Keras, Tensorflow, and Google Colab.
Emphasis on detailed documentation for research integrity and reproducibility.
Usage:
Both papers provide insights into the practical applications and challenges in machine learning. They serve as valuable resources for students, researchers, and practitioners interested in the fields of image classification and model reproducibility in machine learning.

For replication and further research, access to relevant datasets, and understanding of machine learning libraries and tools are necessary.

Note:
The research highlights the importance of precision in experimental setup and documentation in the machine learning domain, promoting the broader understanding and advancement of these technologies.

